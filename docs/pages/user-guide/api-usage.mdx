# API Usage

## Using the API

### Chat Completions

AiMo Network provides an OpenAI-compatible chat completion endpoint:

**Base URL:** `https://devnet.aimo.network/api`

**Endpoint:** `POST /v1/chat/completions`

**Headers:**

```http
Authorization: Bearer aimo-sk-v2-[your-api-key]
Content-Type: application/json
```

**Request Format:**

```json
{
  "model": "openai/gpt-4o",
  "messages": [
    {"role": "user", "content": "Hello, how are you?"}
  ],
  "stream": true,
  "max_tokens": 150,
  "temperature": 0.7
}
```

**Key Fields:**

- `model`: You can specify models in two ways:
  - **Simple format**: `openai/gpt-4o` - Uses intelligent routing to find the best provider
  - **Direct format**: `provider_pubkey:model_name` - Route to a specific provider
- `messages`: Standard OpenAI message format
- `stream`: Set to `true` for streaming responses, `false` for complete responses
- Other standard OpenAI parameters are supported

### Listing Available Models

To see all available models, use the models endpoint:

**Endpoint:** `GET /v1/models`

**Example:**

```bash
curl "https://devnet.aimo.network/api/v1/models" \
  -H "Authorization: Bearer aimo-sk-v2-[your-api-key]"
```

This returns a list of all available models with their capabilities and pricing.

### Example Usage

#### Using curl

```bash
curl -X POST "https://devnet.aimo.network/api/v1/chat/completions" \
  -H "Authorization: Bearer aimo-sk-v2-[your-api-key]" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "openai/gpt-4o",
    "messages": [
      {"role": "user", "content": "Explain quantum computing"}
    ],
    "stream": true,
    "max_tokens": 500
  }'
```

#### Using Python

```python
import requests
import json

url = "https://devnet.aimo.network/api/v1/chat/completions"
headers = {
    "Authorization": "Bearer aimo-sk-v2-[your-api-key]",
    "Content-Type": "application/json"
}

data = {
    "model": "anthropic/claude-3-5-sonnet",
    "messages": [
        {"role": "user", "content": "What is machine learning?"}
    ],
    "stream": False,
    "max_tokens": 300
}

response = requests.post(url, headers=headers, json=data)
print(response.json())
```

#### Using JavaScript/Node.js

```javascript
const response = await fetch('https://devnet.aimo.network/api/v1/chat/completions', {
  method: 'POST',
  headers: {
    'Authorization': 'Bearer aimo-sk-v2-[your-api-key]',
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    model: 'deepseek/deepseek-chat',
    messages: [
      { role: 'user', content: 'Tell me about blockchain technology' }
    ],
    stream: true,
    max_tokens: 400
  })
});

// For streaming responses
const reader = response.body.getReader();
while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  console.log(new TextDecoder().decode(value));
}
```

## Finding Available Models

There are two ways to discover and use models:

### 1. List Models via API

Query the models endpoint to see all available models programmatically:

```bash
curl "https://devnet.aimo.network/api/v1/models" \
  -H "Authorization: Bearer aimo-sk-v2-[your-api-key]"
```

### 2. Browse the Marketplace

Visit [https://aimo.network/marketplace](https://aimo.network/marketplace) to browse available models with their capabilities and pricing.

### Model Specification Formats

You can specify models in two ways:

**Intelligent Routing (Recommended):**
```json
{
  "model": "openai/gpt-4o"
}
```
The system automatically routes to the best available provider for this model.

**Direct Provider:**
```json
{
  "model": "8W7X1tGnWh9CXwnPD7wgke31Gdcqmex4LapJvQ2afBUq:deepseek-chat-v3"
}
```
Routes directly to a specific provider using `provider_pubkey:model_name` format.
