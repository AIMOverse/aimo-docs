# Docker Deployment Guide

## Why Use Docker?

Docker deployment offers several advantages for running the AIMO proxy:

- **No Rust Toolchain Required**: Skip the complexity of installing and managing Rust dependencies locally
- **Frequent Updates**: Easily pull the latest AIMO proxy versions without rebuilding from source
- **Environment Consistency**: Ensure identical behavior across development, staging, and production
- **Simplified Dependencies**: All required dependencies are bundled within the container
- **Easy Scaling**: Leverage Docker's orchestration capabilities for horizontal scaling

## Running AIMO Proxy with Docker

### Prerequisites

Before running the proxy, generate your API key via the [AiMo Network Dashboard](https://aimo.network/account/keys).

### Docker Compose Setup

Create a `compose.yml` file for a more robust deployment:

```yaml
services:
  proxy:
    image: ghcr.io/aimoverse/aimo-proxy:main
    container_name: aimo-proxy
    network_mode: host
    volumes:
      # Mount a specific config file directly
      - ./proxy.dev.toml:/etc/proxy/config.toml
    environment:
      # Default: /etc/proxy/proxy.toml
      CONFIG_FILE_PATH: /etc/proxy/config.toml
```

## Configuration File

### Example Configuration (`proxy.dev.toml`)

:::note
Go to [web dashboard](https://aimo.network/account/keys) to generate a key.
:::

```toml
[router]
url = "https://devnet.aimo.network"
# prefix with `std::env::` to read from env vars
api_key = "std::env::AIMO_PROVIDER_KEY"

# Model metadata
[[models]]
name = "glm-4_5-air-free"
display_name = "DeepSeek Chat V3 0324"
provider_name = "chutesai"
# optional
context_length = 128000
# optional
input_modalities = ["file", "image", "text"]
output_modalities = ["text", "image"]

[models.pricing]
# USDC per million token
prompt = 0.1
# USDC per million token
completion = 1.2
# USDC per image input (optional)
image = 1

# How to access the model
[models.params]
model = "chutesai/zai-org/GLM-4.5-Air"
api_base = "https://api.chutesai.com/v1"
# prefix with `std::env::` to read from env vars
api_key = "std::env::CHUTESAI_API_KEY"

# Add more models by repeating the [[models]] section
# ...
```

## Running Without Docker

If you prefer not to use Docker, you can install and run the proxy directly:

### Install via Cargo

```bash
cargo install aimo-proxy
```

### Run the Proxy

```bash
aimo-proxy --config proxy.dev.toml
```

## Environment Variables

You can use environment variables in your configuration by prefixing values with `std::env::`:

```bash
# Set environment variables
export AIMO_PROVIDER_KEY="aimo-sk-v2-your-provider-key-here"
export CHUTESAI_API_KEY="your-provider-api-key"
```

Then reference them in your config:

```toml
[router]
api_key = "std::env::AIMO_PROVIDER_KEY"

[models.params]
api_key = "std::env::CHUTESAI_API_KEY"
```
